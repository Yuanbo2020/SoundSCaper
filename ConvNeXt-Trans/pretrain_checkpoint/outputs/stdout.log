[2025-03-28 00:27:39,356][dcase24t6.train][INFO] - Full configuration:
ckpt:
  _target_: dcase24t6.callbacks.ckpt.CustomModelCheckpoint
  dirpath: ./logs/train-2025.03.28-00.27.34-baseline/./checkpoints
  monitor: val/loss
  mode: min
  filename: '{epoch:03d}-{step:06d}-mode_min-{val/loss:.4f}'
  replace_slash_in_filename: true
  create_best_symlink: true
datamodule:
  _target_: dcase24t6.datamodules.hdf.HDFDatamodule
  root: ./data
  train_hdfs: custom_train_cnext.hdf
  val_hdfs: custom_val_cnext.hdf
  test_hdfs: custom_val_cnext.hdf
  predict_hdfs:
  - clotho_dcase_aac_analysis_cnext.hdf
  - clotho_dcase_aac_test_cnext.hdf
  train_batch_keys:
  - frame_embs
  - frame_embs_shape
  - captions
  val_batch_keys:
  - frame_embs
  - frame_embs_shape
  - dataset
  - subset
  - fname
  - mult_captions
  - mult_references
  test_batch_keys:
  - frame_embs
  - frame_embs_shape
  - dataset
  - subset
  - fname
  - mult_captions
  - mult_references
  predict_batch_keys:
  - frame_embs
  - frame_embs_shape
  - dataset
  - subset
  - fname
  batch_size: 64
  num_workers: auto
  pin_memory: true
  train_drop_last: false
  verbose: 1
emission:
  _target_: dcase24t6.callbacks.emissions.CustomEmissionTracker
  save_dir: ./logs/train-2025.03.28-00.27.34-baseline/.
  emissions_fname: emissions/{task}_emissions.yaml
  country_iso_code: null
  offline: false
  disabled: false
  experiment_name: train-2025.03.28-00.27.34-baseline
model:
  _target_: dcase24t6.models.trans_decoder.TransDecoderModel
  sched_num_steps: 200
  verbose: 1
  lr: 0.0005
  weight_decay: 2
  beam_size: 3
  d_model: 256
  label_smoothing: 0.2
  mixup_alpha: 0.4
tokenizer:
  _target_: dcase24t6.tokenization.aac_tokenizer.AACTokenizer
path:
  data_root: ./data
  save_root: ./logs
datetime: 2025.03.28-00.27.34
save_dir: ./logs/train-2025.03.28-00.27.34-baseline/.
save_name: train-2025.03.28-00.27.34-baseline
seed: 42
verbose: 1
val_ckpt_path: null
test_ckpt_path: best
logger:
  _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger
  save_dir: ./logs/train-2025.03.28-00.27.34-baseline/.
  name: tensorboard
  version: .
trainer:
  _target_: lightning.pytorch.trainer.Trainer
  accelerator: gpu
  accumulate_grad_batches: 8
  benchmark: false
  detect_anomaly: false
  deterministic: false
  devices: 1
  enable_checkpointing: true
  enable_model_summary: false
  fast_dev_run: false
  gradient_clip_algorithm: norm
  gradient_clip_val: 1
  limit_predict_batches: null
  limit_test_batches: null
  limit_train_batches: null
  limit_val_batches: null
  log_every_n_steps: 5
  max_epochs: 200
  max_steps: -1
  num_nodes: 1
  num_sanity_val_steps: 0
  precision: 32
  reload_dataloaders_every_n_epochs: 0
  val_check_interval: null
evaluator:
  _target_: dcase24t6.callbacks.evaluator.Evaluator
  save_dir: ./logs/train-2025.03.28-00.27.34-baseline/.
  val_metrics:
  - cider_d
  - vocab
  test_metrics: all
  exclude_keys:
  - frame_embs

[2025-03-28 00:27:39,366][sentence_transformers.SentenceTransformer][INFO] - Load pretrained SentenceTransformer: paraphrase-TinyBERT-L6-v2
[2025-03-28 00:27:46,363][dcase24t6.train][INFO] - Adding 7 callbacks: Evaluator, ModelSummary, ComplexityProfiler, LearningRateMonitor, PrintModelHash, CustomModelCheckpoint, EarlyStopping
[2025-03-28 00:27:47,702][dcase24t6.nn.decoding.common][INFO] - Forbid repetition mask 39/48 tokens during testing.
[2025-03-28 17:33:15,496][dcase24t6.train][INFO] - Job results are saved in './logs/train-2025.03.28-00.27.34-baseline/.'. (duration=17:05:41)
